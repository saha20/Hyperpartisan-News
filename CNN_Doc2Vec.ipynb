{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import utils\n",
    "from gensim.models.doc2vec import LabeledSentence\n",
    "from gensim.models import Doc2Vec\n",
    "from gensim.test.utils import get_tmpfile\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "\n",
    "# numpy\n",
    "import numpy as np\n",
    "\n",
    "# classifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# random\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from time import time\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_json=r'E:\\iiit\\Sem3\\Information Extraction And Retrieval\\major_project\\data\\json\\train_data.json'\n",
    "val_json=r'E:\\iiit\\Sem3\\Information Extraction And Retrieval\\major_project\\data\\json\\val_data.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LabeledLineSentence():\n",
    "    def __init__(self,fileName):\n",
    "        self.fileName = fileName\n",
    "        \n",
    "    def __iter__(self):\n",
    "        df = pd.read_json(self.fileName,orient='table')\n",
    "        text = df['clean_text'].values\n",
    "        for idx, doc in tqdm(enumerate(text)):\n",
    "            doc = self.preprocess(doc)\n",
    "            yield TaggedDocument(words=doc.split(),tags=[idx])\n",
    "            \n",
    "    def preprocess(self, doc):\n",
    "        doc = re.sub('[^a-z]',' ',doc.lower())\n",
    "        return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterator=LabeledLineSentence(train_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "600000it [02:43, 3675.93it/s]\n",
      "600000it [06:45, 1477.90it/s]\n",
      "600000it [06:14, 1603.37it/s]\n"
     ]
    }
   ],
   "source": [
    "model = Doc2Vec(iterator,min_count=1, vector_size=250, sample=1e-4, negative=6 ,workers=4,epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "600000it [06:08, 1629.29it/s]\n",
      "600000it [06:16, 1595.66it/s]\n",
      "600000it [06:14, 1601.62it/s]\n",
      "600000it [06:30, 1534.96it/s]\n",
      "600000it [06:28, 1544.69it/s]\n"
     ]
    }
   ],
   "source": [
    "model.train(iterator, total_examples=model.corpus_count, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('doc_2_vec_large.d2v')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load doc2vec model and transform the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc2vec_model=Doc2Vec.load('doc_2_vec_large.d2v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train=pd.read_json(train_json,orient='table')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████| 600000/600000 [48:09<00:00, 207.66it/s]\n"
     ]
    }
   ],
   "source": [
    "train_data=[doc2vec_model.infer_vector(sentence.split()) for sentence in tqdm(df_train['clean_text'].values)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val=pd.read_json(val_json,orient='table')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████| 150000/150000 [13:57<00:00, 179.11it/s]\n"
     ]
    }
   ],
   "source": [
    "val_data=[doc2vec_model.infer_vector(sentence.split()) for sentence in tqdm(df_val['clean_text'].values)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('d2v_train.npy',train_data)\n",
    "np.save('d2v_test.npy',val_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from time import time\n",
    "import re\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout\n",
    "from tensorflow.keras.layers import LSTM,GlobalMaxPooling1D,Bidirectional\n",
    "from tensorflow.keras.layers import Conv1D\n",
    "from tensorflow.keras.layers import MaxPooling1D\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=np.load('d2v_train.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test=np.load('d2v_test.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder,LabelEncoder\n",
    "labels=np.load('hyperpartisan_large.npy',allow_pickle=True)\n",
    "le=LabelEncoder()\n",
    "le_labels=le.fit_transform(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test=np.load('hyperpartisan_small.npy',allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Bidirectional(LSTM(150, return_sequences=True, dropout=0.1, recurrent_dropout=0.0)))\n",
    "\n",
    "model.add(Conv1D(filters=64, kernel_size=8, padding='same', activation='relu', \n",
    "                 input_shape=(250,1),kernel_initializer= 'glorot_uniform'))\n",
    "model.add(MaxPooling1D(pool_size=4))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Conv1D(filters=32, kernel_size=8, padding='same', activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=4))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Conv1D(filters=32, kernel_size=8, padding='same', activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=4))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Conv1D(filters=32, kernel_size=3, padding='same', activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=3))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Dense(64,activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "\n",
    "model.add(Dense(32,activation='relu'))\n",
    "model.add(Dropout(0.1))\n",
    "\n",
    "model.add(Dense(16,activation='relu'))\n",
    "model.add(Dense(2))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.compile(optimizer=Adam(learning_rate=1e-4),loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# .reshape(600000,250,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#X_train.reshape((train_size,classification_dim,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1055/1055 [==============================] - 65s 62ms/step - loss: 0.6863 - accuracy: 0.5449 - val_loss: 0.6857 - val_accuracy: 0.5535\n",
      "Epoch 2/10\n",
      "1055/1055 [==============================] - 62s 58ms/step - loss: 0.6812 - accuracy: 0.5594 - val_loss: 0.6874 - val_accuracy: 0.5409\n",
      "Epoch 3/10\n",
      "1055/1055 [==============================] - 62s 59ms/step - loss: 0.6787 - accuracy: 0.5624 - val_loss: 0.6869 - val_accuracy: 0.5447\n",
      "Epoch 4/10\n",
      "1055/1055 [==============================] - 62s 59ms/step - loss: 0.6777 - accuracy: 0.5634 - val_loss: 0.6876 - val_accuracy: 0.5405\n",
      "Epoch 5/10\n",
      "1055/1055 [==============================] - 63s 60ms/step - loss: 0.6753 - accuracy: 0.5697 - val_loss: 0.6841 - val_accuracy: 0.5512\n",
      "Epoch 6/10\n",
      "1055/1055 [==============================] - 65s 62ms/step - loss: 0.6707 - accuracy: 0.5806 - val_loss: 0.6749 - val_accuracy: 0.5729\n",
      "Epoch 7/10\n",
      "1055/1055 [==============================] - 65s 61ms/step - loss: 0.6632 - accuracy: 0.5964 - val_loss: 0.6712 - val_accuracy: 0.5892\n",
      "Epoch 8/10\n",
      "1055/1055 [==============================] - 64s 61ms/step - loss: 0.6540 - accuracy: 0.6137 - val_loss: 0.6745 - val_accuracy: 0.5977\n",
      "Epoch 9/10\n",
      "1055/1055 [==============================] - 67s 63ms/step - loss: 0.6471 - accuracy: 0.6264 - val_loss: 0.6788 - val_accuracy: 0.5980\n",
      "Epoch 10/10\n",
      "1055/1055 [==============================] - 66s 62ms/step - loss: 0.6419 - accuracy: 0.6319 - val_loss: 0.6530 - val_accuracy: 0.6329\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x226ff7f4c88>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size=128\n",
    "\n",
    "model.fit(x_test.reshape(150000,250,1),le.transform(y_test),validation_split=0.1,shuffle=True, epochs=10,batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18750/18750 [==============================] - 235s 13ms/step - loss: 0.7352 - accuracy: 0.5194\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.7351899743080139, 0.519361674785614]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x.reshape(600000,250,1),le_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_estimators=400,max_depth=90,n_jobs=-1,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  8.2min\n",
      "[Parallel(n_jobs=-1)]: Done 400 out of 400 | elapsed: 17.4min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=90, n_estimators=400, n_jobs=-1, verbose=1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(x,le_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test=np.load('d2v_test.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    3.1s\n",
      "[Parallel(n_jobs=8)]: Done 400 out of 400 | elapsed:    6.8s finished\n"
     ]
    }
   ],
   "source": [
    "preds=clf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "actuals=np.load('hyperpartisan_small.npy',allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score,f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6439221067973042"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(le.transform(actuals),preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5537133333333333"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(le.transform(actuals),preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
